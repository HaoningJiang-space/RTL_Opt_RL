#!/bin/bash

# RTLä¼˜åŒ–è®­ç»ƒè„šæœ¬ - å®Œå…¨åŸºäºReMAæ¡†æ¶
# ä½¿ç”¨ReMAçš„PPOè®­ç»ƒå™¨å’Œè‡ªå®šä¹‰RTL rewardå‡½æ•°

set -e

# è·å–è„šæœ¬ç›®å½•å’Œé¡¹ç›®æ ¹ç›®å½•
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/../.." && pwd)"

# é»˜è®¤é…ç½®
CONFIG_NAME="rtl_ppo_trainer"
WORKSPACE=${WORKSPACE:-$PROJECT_ROOT}
PROJECT_NAME=${PROJECT_NAME:-"rtl_optimization"}
EXPERIMENT_NAME=${EXPERIMENT_NAME:-"rtl_rema_$(date +%Y%m%d_%H%M%S)"}
MODEL_PATH=${MODEL_PATH:-"deepseek-ai/deepseek-coder-6.7b-instruct"}

# è®­ç»ƒå‚æ•°
NNODES=${NNODES:-1}
GPUS_PER_NODE=${GPUS_PER_NODE:-$(nvidia-smi --query-gpu=name --format=csv,noheader 2>/dev/null | wc -l || echo 1)}
TOTAL_EPOCHS=${TOTAL_EPOCHS:-20}
TOTAL_STEPS=${TOTAL_STEPS:-1000}

# æ•°æ®è·¯å¾„
DATA_DIR="$PROJECT_ROOT/data/rtl_optimization"
TRAIN_FILE="$DATA_DIR/train.parquet"
VAL_FILE="$DATA_DIR/val.parquet"

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

print_info() { echo -e "${BLUE}[INFO]${NC} $1"; }
print_success() { echo -e "${GREEN}[SUCCESS]${NC} $1"; }
print_warning() { echo -e "${YELLOW}[WARNING]${NC} $1"; }
print_error() { echo -e "${RED}[ERROR]${NC} $1"; }

show_help() {
    cat << EOF
RTLä¼˜åŒ–è®­ç»ƒè„šæœ¬ - åŸºäºReMAæ¡†æ¶

ç”¨æ³•: $0 [é€‰é¡¹]

åŸºç¡€é€‰é¡¹:
  -c, --config CONFIG        é…ç½®æ–‡ä»¶å (é»˜è®¤: $CONFIG_NAME)
  -p, --project PROJECT      é¡¹ç›®åç§° (é»˜è®¤: $PROJECT_NAME)
  -e, --experiment EXP       å®éªŒåç§° (é»˜è®¤: auto-generated)
  -M, --model MODEL_PATH     æ¨¡å‹è·¯å¾„ (é»˜è®¤: $MODEL_PATH)

è®­ç»ƒé€‰é¡¹:
  --nnodes N                èŠ‚ç‚¹æ•°é‡ (é»˜è®¤: $NNODES)
  --gpus N                  æ¯èŠ‚ç‚¹GPUæ•° (é»˜è®¤: auto-detect)
  --epochs N                è®­ç»ƒè½®æ•° (é»˜è®¤: $TOTAL_EPOCHS)
  --steps N                 è®­ç»ƒæ­¥æ•° (é»˜è®¤: $TOTAL_STEPS)

æ•°æ®é€‰é¡¹:
  --data-dir DIR            æ•°æ®ç›®å½• (é»˜è®¤: $DATA_DIR)
  --generate-data           è‡ªåŠ¨ç”Ÿæˆè®­ç»ƒæ•°æ®
  --quick-test              å¿«é€Ÿæµ‹è¯•æ¨¡å¼

å…¶ä»–é€‰é¡¹:
  --dry-run                 æ˜¾ç¤ºå‘½ä»¤ä½†ä¸æ‰§è¡Œ
  -h, --help                æ˜¾ç¤ºå¸®åŠ©

ç¤ºä¾‹:
  # æ ‡å‡†è®­ç»ƒ
  $0

  # å¿«é€Ÿæµ‹è¯•
  $0 --quick-test --generate-data

  # è‡ªå®šä¹‰é…ç½®
  $0 --config rtl_quick_test --epochs 5 --steps 100

ç¯å¢ƒå˜é‡:
  WORKSPACE          å·¥ä½œç©ºé—´è·¯å¾„
  PROJECT_NAME       é¡¹ç›®åç§°
  EXPERIMENT_NAME    å®éªŒåç§°
  MODEL_PATH         æ¨¡å‹è·¯å¾„
  CUDA_VISIBLE_DEVICES GPUè®¾å¤‡

EOF
}

# è§£æå‘½ä»¤è¡Œå‚æ•°
GENERATE_DATA=false
QUICK_TEST=false
DRY_RUN=false

while [[ $# -gt 0 ]]; do
    case $1 in
        -c|--config)
            CONFIG_NAME="$2"
            shift 2
            ;;
        -p|--project)
            PROJECT_NAME="$2"
            shift 2
            ;;
        -e|--experiment)
            EXPERIMENT_NAME="$2"
            shift 2
            ;;
        -M|--model)
            MODEL_PATH="$2"
            shift 2
            ;;
        --nnodes)
            NNODES="$2"
            shift 2
            ;;
        --gpus)
            GPUS_PER_NODE="$2"
            shift 2
            ;;
        --epochs)
            TOTAL_EPOCHS="$2"
            shift 2
            ;;
        --steps)
            TOTAL_STEPS="$2"
            shift 2
            ;;
        --data-dir)
            DATA_DIR="$2"
            TRAIN_FILE="$DATA_DIR/train.parquet"
            VAL_FILE="$DATA_DIR/val.parquet"
            shift 2
            ;;
        --generate-data)
            GENERATE_DATA=true
            shift
            ;;
        --quick-test)
            QUICK_TEST=true
            CONFIG_NAME="rtl_quick_test"
            PROJECT_NAME="rtl_quick_test"
            DATA_DIR="$PROJECT_ROOT/data/rtl_test"
            TRAIN_FILE="$DATA_DIR/train.parquet"
            VAL_FILE="$DATA_DIR/val.parquet"
            TOTAL_EPOCHS=3
            TOTAL_STEPS=50
            GENERATE_DATA=true
            shift
            ;;
        --dry-run)
            DRY_RUN=true
            shift
            ;;
        -h|--help)
            show_help
            exit 0
            ;;
        *)
            print_error "æœªçŸ¥é€‰é¡¹: $1"
            show_help
            exit 1
            ;;
    esac
done

# è¿›å…¥é¡¹ç›®æ ¹ç›®å½•
cd "$PROJECT_ROOT"

print_info "=================================="
print_info "RTLä¼˜åŒ–è®­ç»ƒ - ReMAæ¡†æ¶"
print_info "=================================="
print_info "é¡¹ç›®ç›®å½•: $PROJECT_ROOT"
print_info "é…ç½®åç§°: $CONFIG_NAME"
print_info "é¡¹ç›®åç§°: $PROJECT_NAME"
print_info "å®éªŒåç§°: $EXPERIMENT_NAME"
print_info "æ¨¡å‹è·¯å¾„: $MODEL_PATH"
print_info "èŠ‚ç‚¹æ•°é‡: $NNODES"
print_info "GPUæ•°é‡: $GPUS_PER_NODE"
print_info "è®­ç»ƒè½®æ•°: $TOTAL_EPOCHS"
print_info "è®­ç»ƒæ­¥æ•°: $TOTAL_STEPS"
print_info "æ•°æ®ç›®å½•: $DATA_DIR"

# æ£€æŸ¥é…ç½®æ–‡ä»¶
CONFIG_PATH="src/verl/verl/rema_trainer/config/${CONFIG_NAME}.yaml"
if [[ ! -f "$CONFIG_PATH" ]]; then
    print_error "é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: $CONFIG_PATH"
    print_info "å¯ç”¨é…ç½®æ–‡ä»¶ï¼š"
    ls src/verl/verl/rema_trainer/config/*.yaml | xargs basename -s .yaml
    exit 1
fi
print_success "é…ç½®æ–‡ä»¶: $CONFIG_PATH"

# æ£€æŸ¥Pythonç¯å¢ƒ
print_info "æ£€æŸ¥Pythonç¯å¢ƒ..."
if ! command -v python &> /dev/null; then
    print_error "Pythonæœªæ‰¾åˆ°"
    exit 1
fi

python_version=$(python --version 2>&1)
print_success "Python: $python_version"

# æ£€æŸ¥å…³é”®ä¾èµ–
print_info "æ£€æŸ¥ä¾èµ–..."
python -c "import torch; print(f'PyTorch: {torch.__version__}')" || { print_error "PyTorchæœªå®‰è£…"; exit 1; }
python -c "import transformers; print(f'Transformers: {transformers.__version__}')" || { print_error "Transformersæœªå®‰è£…"; exit 1; }
python -c "import verl; print('VeRL: å¯ç”¨')" || { print_error "VeRLæ¡†æ¶æœªå®‰è£…"; exit 1; }

# æ£€æŸ¥GPU
if command -v nvidia-smi &> /dev/null; then
    print_success "æ£€æµ‹åˆ° $GPUS_PER_NODE ä¸ªGPU"
    nvidia-smi --query-gpu=name,memory.total --format=csv,noheader,nounits | nl -v0 | while read gpu_info; do
        print_info "GPU $gpu_info"
    done
else
    print_warning "æœªæ£€æµ‹åˆ°NVIDIA GPU"
    GPUS_PER_NODE=0
fi

# æ£€æŸ¥éªŒè¯å·¥å…·
print_info "æ£€æŸ¥VerilogéªŒè¯å·¥å…·..."
for tool in verilator yosys iverilog; do
    if command -v $tool &> /dev/null; then
        version=$(timeout 5s $tool --version 2>&1 | head -1 || echo "ç‰ˆæœ¬æœªçŸ¥")
        print_success "$tool: $version"
    else
        print_warning "$tool: ä¸å¯ç”¨"
    fi
done

# ç”Ÿæˆæ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
if [[ "$GENERATE_DATA" == "true" ]] || [[ ! -f "$TRAIN_FILE" ]] || [[ ! -f "$VAL_FILE" ]]; then
    print_info "ç”ŸæˆRTLè®­ç»ƒæ•°æ®..."

    if [[ "$QUICK_TEST" == "true" ]]; then
        python scripts/data/generate_rtl_data.py --quick --output_dir "$DATA_DIR"
    else
        python scripts/data/generate_rtl_data.py --num_samples 500 --output_dir "$DATA_DIR"
    fi

    if [[ $? -eq 0 ]]; then
        print_success "æ•°æ®ç”Ÿæˆå®Œæˆ"
    else
        print_error "æ•°æ®ç”Ÿæˆå¤±è´¥"
        exit 1
    fi
else
    print_success "ä½¿ç”¨ç°æœ‰è®­ç»ƒæ•°æ®"
fi

# éªŒè¯æ•°æ®æ–‡ä»¶
if [[ ! -f "$TRAIN_FILE" ]]; then
    print_error "è®­ç»ƒæ•°æ®ä¸å­˜åœ¨: $TRAIN_FILE"
    exit 1
fi

if [[ ! -f "$VAL_FILE" ]]; then
    print_error "éªŒè¯æ•°æ®ä¸å­˜åœ¨: $VAL_FILE"
    exit 1
fi

print_success "è®­ç»ƒæ•°æ®: $TRAIN_FILE"
print_success "éªŒè¯æ•°æ®: $VAL_FILE"

# åˆ›å»ºå¿…è¦çš„ç›®å½•
mkdir -p logs models

# æ„å»ºè®­ç»ƒå‘½ä»¤
TRAIN_CMD="python -m verl.rema_trainer.main_ppo"

# æ„å»ºå‚æ•°åˆ—è¡¨
TRAIN_ARGS=(
    "trainer.project_name=$PROJECT_NAME"
    "trainer.experiment_name=$EXPERIMENT_NAME"
    "trainer.nnodes=$NNODES"
    "trainer.n_gpus_per_node=$GPUS_PER_NODE"
    "trainer.total_epochs=$TOTAL_EPOCHS"
    "trainer.total_training_steps=$TOTAL_STEPS"
    "data.train_files=$TRAIN_FILE"
    "data.val_files=$VAL_FILE"
    "actor_rollout_ref.model.path=$MODEL_PATH"
    "--config-path=src/verl/verl/rema_trainer/config"
    "--config-name=$CONFIG_NAME"
)

# æ·»åŠ é¢å¤–çš„è®­ç»ƒå‚æ•°
if [[ "$QUICK_TEST" == "true" ]]; then
    TRAIN_ARGS+=(
        "data.train_batch_size=16"
        "actor_rollout_ref.rollout.n=2"
        "actor_rollout_ref.rollout.max_num_turns=5"
    )
fi

# æ˜¾ç¤ºå®Œæ•´å‘½ä»¤
print_info "è®­ç»ƒå‘½ä»¤:"
echo -e "${BLUE}$TRAIN_CMD \\"
for arg in "${TRAIN_ARGS[@]}"; do
    echo "    $arg \\"
done
echo -e "${NC}"

# æ‰§è¡Œæ£€æŸ¥
print_info "æ‰§è¡Œå‰æ£€æŸ¥..."

# æµ‹è¯•rewardå‡½æ•°
print_info "æµ‹è¯•RTLå¥–åŠ±å‡½æ•°..."
python -c "
from src.verl.verl.utils.reward_score.rtl_optimization import compute_score
test_code = '''module test(input clk, output reg [7:0] out); always @(posedge clk) out <= 8'h42; endmodule'''
score = compute_score('rtl_optimization', 'Optimized code: ' + test_code, test_code)
print(f'RTLå¥–åŠ±å‡½æ•°æµ‹è¯•: {score:.3f}')
assert 0 <= score <= 1, 'å¥–åŠ±åˆ†æ•°åº”åœ¨0-1èŒƒå›´å†…'
print('âœ“ RTLå¥–åŠ±å‡½æ•°æ­£å¸¸å·¥ä½œ')
" || { print_error "RTLå¥–åŠ±å‡½æ•°æµ‹è¯•å¤±è´¥"; exit 1; }

if [[ "$DRY_RUN" == "true" ]]; then
    print_warning "DRY RUNæ¨¡å¼ - å‘½ä»¤æœªæ‰§è¡Œ"
    exit 0
fi

# æœ€ç»ˆç¡®è®¤
print_warning "å³å°†å¼€å§‹è®­ç»ƒï¼Œè¯·ç¡®è®¤ï¼š"
print_warning "1. GPUå†…å­˜å……è¶³"
print_warning "2. ç£ç›˜ç©ºé—´å……è¶³"
print_warning "3. ç½‘ç»œè¿æ¥æ­£å¸¸"
if [[ "$QUICK_TEST" == "false" ]]; then
    print_warning "4. è¿™ä¸æ˜¯æµ‹è¯•ï¼Œå°†è¿›è¡Œå®Œæ•´è®­ç»ƒ"
fi

read -p "æŒ‰Enterç»§ç»­ï¼Œæˆ–Ctrl+Cå–æ¶ˆ..." -t 10 || echo ""

print_info "ğŸš€ å¼€å§‹RTLä¼˜åŒ–è®­ç»ƒ..."
echo

# æ‰§è¡Œè®­ç»ƒ
exec $TRAIN_CMD "${TRAIN_ARGS[@]}"