#!/usr/bin/env python3
"""
RTL Optimization Data Generation Script
Generate RTL optimization training data in ReMA framework format
"""

import argparse
import json
import pandas as pd
import random
from pathlib import Path
from typing import List, Dict, Any


def generate_basic_verilog(module_name: str, complexity: str = "simple") -> str:
    """Generate basic Verilog code"""

    if complexity == "simple":
        return f'''module {module_name}(
    input clk,
    input rst,
    input [7:0] data_in,
    output reg [7:0] data_out
);
    reg [7:0] temp_reg;

    always @(posedge clk) begin
        if (rst) begin
            temp_reg <= 8'b0;
            data_out <= 8'b0;
        end else begin
            temp_reg <= data_in + 1;
            data_out <= temp_reg;
        end
    end
endmodule'''

    elif complexity == "medium":
        return f'''module {module_name}(
    input clk,
    input rst,
    input [15:0] a,
    input [15:0] b,
    input [1:0] op,
    output reg [31:0] result
);
    reg [31:0] temp_a, temp_b;
    reg [31:0] intermediate;

    always @(posedge clk) begin
        if (rst) begin
            temp_a <= 0;
            temp_b <= 0;
            intermediate <= 0;
            result <= 0;
        end else begin
            temp_a <= {{16'b0, a}};
            temp_b <= {{16'b0, b}};

            case (op)
                2'b00: intermediate <= temp_a + temp_b;
                2'b01: intermediate <= temp_a - temp_b;
                2'b10: intermediate <= temp_a * temp_b;
                2'b11: intermediate <= temp_a & temp_b;
            endcase

            result <= intermediate;
        end
    end
endmodule'''

    else:  # complex
        return f'''module {module_name}(
    input clk,
    input rst,
    input [31:0] data_in,
    input valid_in,
    output reg [31:0] data_out,
    output reg valid_out
);
    reg [31:0] stage1_data, stage2_data, stage3_data;
    reg stage1_valid, stage2_valid, stage3_valid;
    reg [31:0] temp1, temp2, temp3;

    // First pipeline stage
    always @(posedge clk) begin
        if (rst) begin
            stage1_data <= 0;
            stage1_valid <= 0;
            temp1 <= 0;
        end else begin
            if (valid_in) begin
                temp1 <= data_in + 32'h12345678;
                stage1_data <= temp1;
                stage1_valid <= 1;
            end else begin
                stage1_valid <= 0;
            end
        end
    end

    // Second pipeline stage
    always @(posedge clk) begin
        if (rst) begin
            stage2_data <= 0;
            stage2_valid <= 0;
            temp2 <= 0;
        end else begin
            temp2 <= stage1_data ^ 32'hABCDEF00;
            stage2_data <= temp2;
            stage2_valid <= stage1_valid;
        end
    end

    // Third pipeline stage
    always @(posedge clk) begin
        if (rst) begin
            stage3_data <= 0;
            stage3_valid <= 0;
            temp3 <= 0;
            data_out <= 0;
            valid_out <= 0;
        end else begin
            temp3 <= stage2_data << 2;
            stage3_data <= temp3;
            stage3_valid <= stage2_valid;

            data_out <= stage3_data;
            valid_out <= stage3_valid;
        end
    end
endmodule'''


def generate_optimized_verilog(original_code: str, optimization_type: str) -> tuple[str, str]:
    """Generate optimized version based on original code"""

    module_name = extract_module_name(original_code) + "_opt"

    if "temp_reg" in original_code and optimization_type in ["area", "timing"]:
        # Area/timing optimization: remove intermediate register
        optimized = original_code.replace("reg [7:0] temp_reg;", "")
        optimized = optimized.replace("temp_reg <= data_in + 1;", "")
        optimized = optimized.replace("data_out <= temp_reg;", "data_out <= data_in + 1;")
        optimized = optimized.replace(extract_module_name(original_code), module_name)

        optimization_desc = "Optimization Strategy:\n1. Eliminate intermediate register temp_reg, directly calculate output\n2. Reduce one clock cycle delay\n3. Save area resources"

    elif "intermediate" in original_code and optimization_type == "pipeline":
        # æµæ°´çº¿ä¼˜åŒ–
        lines = original_code.split('\n')
        optimized_lines = []

        for line in lines:
            if "case (op)" in line:
                # æ’å…¥æµæ°´çº¿å¯„å­˜å™¨
                optimized_lines.append("            // æµæ°´çº¿ä¼˜åŒ–ï¼šå°†è¿ç®—åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µ")
                optimized_lines.append("            reg [1:0] op_reg;")
                optimized_lines.append("            op_reg <= op;")
            optimized_lines.append(line)

        optimized = '\n'.join(optimized_lines)
        optimized = optimized.replace(extract_module_name(original_code), module_name)
        optimization_desc = "ä¼˜åŒ–ç­–ç•¥ï¼š\n1. æ·»åŠ æµæ°´çº¿å¯„å­˜å™¨æé«˜æ—¶é’Ÿé¢‘ç‡\n2. æ”¹å–„æ—¶åºæ€§èƒ½\n3. æ”¯æŒæ›´é«˜çš„å·¥ä½œé¢‘ç‡"

    elif optimization_type == "power":
        # åŠŸè€—ä¼˜åŒ–ï¼šæ·»åŠ æ—¶é’Ÿé—¨æ§
        optimized = original_code.replace(
            "always @(posedge clk) begin",
            "// åŠŸè€—ä¼˜åŒ–ï¼šæ·»åŠ æ—¶é’Ÿé—¨æ§\n    wire gated_clk = clk & (valid_in | ~rst);\n    \n    always @(posedge gated_clk) begin"
        )
        optimized = optimized.replace(extract_module_name(original_code), module_name)
        optimization_desc = "ä¼˜åŒ–ç­–ç•¥ï¼š\n1. æ·»åŠ æ—¶é’Ÿé—¨æ§å‡å°‘åŠ¨æ€åŠŸè€—\n2. åœ¨æ— æ•ˆæ•°æ®æ—¶åœæ­¢æ—¶é’Ÿ\n3. é™ä½æ•´ä½“åŠŸè€—æ¶ˆè€—"

    else:
        # é»˜è®¤ä¼˜åŒ–ï¼šä»£ç æ¸…ç†
        optimized = original_code.replace("    reg [31:0] temp1, temp2, temp3;",
                                        "    reg [31:0] temp1, temp2;  // å‡å°‘ä¸å¿…è¦çš„ä¸´æ—¶å˜é‡")
        optimized = optimized.replace(extract_module_name(original_code), module_name)
        optimization_desc = "ä¼˜åŒ–ç­–ç•¥ï¼š\n1. æ¸…ç†ä¸å¿…è¦çš„å˜é‡å£°æ˜\n2. æ”¹å–„ä»£ç å¯è¯»æ€§\n3. å‡å°‘èµ„æºä½¿ç”¨"

    return optimized, optimization_desc


def extract_module_name(verilog_code: str) -> str:
    """æå–æ¨¡å—å"""
    import re
    match = re.search(r'module\s+(\w+)', verilog_code)
    return match.group(1) if match else "unknown"


def create_rema_conversation(original_code: str, optimized_code: str, optimization_desc: str,
                           optimization_type: str) -> List[Dict[str, str]]:
    """Create ReMA format multi-turn conversation - multi-agent RTL optimization"""

    # æ„å»ºä¸“ä¸šçš„RTLä¼˜åŒ–æç¤º
    question = f"""You are a professional multi-agent RTL optimization system. Please analyze and optimize the following Verilog code.

**Agent Roles:**
- MetaOptimizer: Responsible for high-level strategy planning and optimization direction
- CodeRewriter: Responsible for concrete code rewriting and optimization implementation

**Optimization Target:** {optimization_type} optimization

**Original RTL Code:**
```verilog
{original_code}
```

**Requirements:**
1. As MetaOptimizer, first perform deep analysis and strategy planning
2. As CodeRewriter, implement specific optimizations based on the strategy
3. Maintain functional equivalence
4. Consider synthesis tool characteristics (e.g., Yosys)
5. Follow RTL optimization best practices

Please proceed with multi-agent collaborative optimization."""

    # Meta-thinkingå›ç­” (MetaOptimizerè§’è‰²)
    meta_thinking = f"""**MetaOptimizer Analysis:**

ğŸ” **RTL Design Analysis**
- Module: {extract_module_name(original_code)}
- Architecture: {"Sequential logic" if "always @(posedge" in original_code else "Combinational logic"}
- Complexity: {"High" if len(original_code.split('\\n')) > 50 else "Medium" if len(original_code.split('\\n')) > 20 else "Low"}

ğŸ“Š **Optimization Potential Identification**
- Data path: {"Pipeline opportunities exist" if "stage" in original_code else "Combinational logic optimization opportunities"}
- Resource usage: {"Register usage can be optimized" if "reg" in original_code else "Combinational logic can be optimized"}
- Timing characteristics: {"Multi-clock domain" if original_code.count("clk") > 1 else "Single clock domain design"}

ğŸ¯ **{optimization_type.title()} Optimization Strategy**
- Primary strategy: {"Reduce critical path delay" if optimization_type == "timing" else "Reduce hardware resources" if optimization_type == "area" else "Lower dynamic power consumption" if optimization_type == "power" else "Balanced optimization"}
- Technical approach: {"Pipeline restructuring" if "pipeline" in optimization_type else "Logic simplification and sharing"}
- Constraints: Maintain interface compatibility and functional equivalence

ğŸ’¡ **Implementation Path**
- Step 1: {"Analyze critical paths" if optimization_type == "timing" else "Identify redundant resources" if optimization_type == "area" else "Locate power hotspots"}
- Step 2: {"Restructure data paths" if optimization_type != "power" else "Add clock gating"}
- Step 3: Verify optimization effectiveness and functional correctness"""

    # Reasoningå›ç­” (CodeRewriterè§’è‰²)
    reasoning = f"""**CodeRewriter Implementation:**

Based on MetaOptimizer's analysis, I have implemented the following optimization:

```verilog
{optimized_code}
```

ğŸ”§ **Specific Optimization Implementation**
{optimization_desc}

âš¡ **Optimization Techniques Explained**
- **Algorithm level:** {"Parallel computation to reduce latency" if optimization_type == "timing" else "Eliminate redundant computation and storage" if optimization_type == "area" else "Introduce conditional computation to reduce power"}
- **Architecture level:** {"Restructure dataflow for higher parallelism" if "pipeline" in optimization_type else "Simplify control logic"}
- **Implementation level:** Follow Verilog synthesis best practices

ğŸ“ˆ **Expected Improvement**
- **{optimization_type.title()} metrics:** {"Latency reduced by 10-30%" if optimization_type == "timing" else "Area reduced by 15-25%" if optimization_type == "area" else "Power reduced by 20-40%" if optimization_type == "power" else "Overall metrics improved"}
- **Synthesis quality:** After Yosys synthesis, expect {"better timing convergence" if optimization_type == "timing" else "fewer LUT usage" if optimization_type == "area" else "lower dynamic power"}
- **Code quality:** Maintain readability and maintainability

âœ… **Verification Checklist**
- [x] Functional equivalence: All output logic remains consistent
- [x] Interface compatibility: Port definitions completely match
- [x] Synthesis-friendly: Avoided structures difficult for synthesis tools
- [x] Timing constraints: {"Optimized critical paths" if optimization_type == "timing" else "No additional timing issues introduced"}"""

    return [
        {"role": "user", "content": question},
        {"role": "meta_thinking", "content": meta_thinking},
        {"role": "reasoning", "content": reasoning}
    ]


def generate_rtl_dataset(num_samples: int, output_dir: str, data_source: str = "rtl_optimization"):
    """ç”ŸæˆRTLä¼˜åŒ–æ•°æ®é›†"""

    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    train_data = []
    val_data = []

    complexities = ["simple", "medium", "complex"]
    optimization_types = ["area", "timing", "power", "pipeline"]

    print(f"ç”Ÿæˆ {num_samples} ä¸ªRTLä¼˜åŒ–æ ·æœ¬...")

    for i in range(num_samples):
        complexity = random.choice(complexities)
        opt_type = random.choice(optimization_types)
        module_name = f"rtl_module_{i}"

        # ç”ŸæˆåŸå§‹å’Œä¼˜åŒ–ä»£ç 
        original_code = generate_basic_verilog(module_name, complexity)
        optimized_code, optimization_desc = generate_optimized_verilog(original_code, opt_type)

        # åˆ›å»ºReMAæ ¼å¼å¯¹è¯
        conversation = create_rema_conversation(original_code, optimized_code,
                                              optimization_desc, opt_type)

        # æ„å»ºæ•°æ®é¡¹
        data_item = {
            "data_source": data_source,
            "question": conversation[0]["content"],  # ç”¨æˆ·é—®é¢˜
            "response": conversation[2]["content"],  # æœ€ç»ˆå›ç­”
            "history": conversation,  # å®Œæ•´å¯¹è¯å†å²
            "ground_truth": optimized_code,  # æ ‡å‡†ç­”æ¡ˆï¼ˆä¼˜åŒ–ä»£ç ï¼‰
            "original_code": original_code,  # åŸå§‹ä»£ç 
            "optimization_type": opt_type,
            "complexity": complexity,
            "module_name": module_name,
            "extra_info": {
                "original_code": original_code,
                "optimization_goal": opt_type,
                "expected_improvement": {
                    "area": random.uniform(0.05, 0.25) if opt_type == "area" else random.uniform(-0.05, 0.15),
                    "timing": random.uniform(0.08, 0.30) if opt_type == "timing" else random.uniform(-0.02, 0.12),
                    "power": random.uniform(0.03, 0.20) if opt_type == "power" else random.uniform(-0.03, 0.10)
                }
            }
        }

        # åˆ’åˆ†è®­ç»ƒå’ŒéªŒè¯é›†ï¼ˆ80-20ï¼‰
        if i < num_samples * 0.8:
            train_data.append(data_item)
        else:
            val_data.append(data_item)

    # ä¿å­˜ä¸ºparquetæ ¼å¼
    train_df = pd.DataFrame(train_data)
    val_df = pd.DataFrame(val_data)

    train_path = output_path / "train.parquet"
    val_path = output_path / "val.parquet"

    train_df.to_parquet(train_path, index=False)
    val_df.to_parquet(val_path, index=False)

    print(f"âœ“ ç”Ÿæˆè®­ç»ƒæ•°æ®: {len(train_data)} ä¸ªæ ·æœ¬ -> {train_path}")
    print(f"âœ“ ç”ŸæˆéªŒè¯æ•°æ®: {len(val_data)} ä¸ªæ ·æœ¬ -> {val_path}")

    # ç”ŸæˆJSONæ ¼å¼çš„æ ·æœ¬ï¼ˆç”¨äºè°ƒè¯•ï¼‰
    sample_json = output_path / "sample_data.json"
    with open(sample_json, 'w', encoding='utf-8') as f:
        json.dump({
            "train_sample": train_data[0] if train_data else {},
            "val_sample": val_data[0] if val_data else {},
            "statistics": {
                "total_samples": num_samples,
                "train_samples": len(train_data),
                "val_samples": len(val_data),
                "data_source": data_source,
                "complexities": complexities,
                "optimization_types": optimization_types
            }
        }, f, indent=2, ensure_ascii=False)

    print(f"âœ“ ç”Ÿæˆæ ·æœ¬æ–‡ä»¶: {sample_json}")
    return train_path, val_path


def main():
    parser = argparse.ArgumentParser(description="ç”ŸæˆRTLä¼˜åŒ–è®­ç»ƒæ•°æ®")
    parser.add_argument("--num_samples", type=int, default=200,
                       help="ç”Ÿæˆçš„æ ·æœ¬æ•°é‡ (é»˜è®¤: 200)")
    parser.add_argument("--output_dir", type=str, default="data/rtl_optimization",
                       help="è¾“å‡ºç›®å½• (é»˜è®¤: data/rtl_optimization)")
    parser.add_argument("--data_source", type=str, default="rtl_optimization",
                       help="æ•°æ®æºåç§° (é»˜è®¤: rtl_optimization)")
    parser.add_argument("--quick", action="store_true",
                       help="å¿«é€Ÿæ¨¡å¼ï¼šç”Ÿæˆè¾ƒå°‘æ ·æœ¬ç”¨äºæµ‹è¯•")

    args = parser.parse_args()

    if args.quick:
        args.num_samples = 50
        args.output_dir = "data/rtl_test"
        print("ğŸš€ å¿«é€Ÿæ¨¡å¼ï¼šç”Ÿæˆå°‘é‡æ•°æ®ç”¨äºæµ‹è¯•")

    print("=" * 60)
    print("RTLä¼˜åŒ–æ•°æ®ç”Ÿæˆå™¨")
    print("=" * 60)
    print(f"æ ·æœ¬æ•°é‡: {args.num_samples}")
    print(f"è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"æ•°æ®æº: {args.data_source}")

    try:
        train_path, val_path = generate_rtl_dataset(
            num_samples=args.num_samples,
            output_dir=args.output_dir,
            data_source=args.data_source
        )

        print("\nâœ… æ•°æ®ç”Ÿæˆå®Œæˆï¼")
        print(f"è®­ç»ƒæ•°æ®: {train_path}")
        print(f"éªŒè¯æ•°æ®: {val_path}")
        print("\nå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¼€å§‹è®­ç»ƒï¼š")
        print(f"python src/verl/verl/rema_trainer/main_ppo.py \\")
        print(f"  data.train_files={train_path} \\")
        print(f"  data.val_files={val_path} \\")
        print(f"  --config-name rtl_ppo_trainer")

    except Exception as e:
        print(f"âŒ æ•°æ®ç”Ÿæˆå¤±è´¥: {e}")
        return 1

    return 0


if __name__ == "__main__":
    exit(main())